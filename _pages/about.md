---
permalink: /
title: "Susav Shrestha"
excerpt: "About me"
author_profile: true
# toc: true
# toc_sticky: true
redirect_from:
  - /about/
  - /about.html
---

<head>
  <meta name="description" content="Susav is a PhD candidate at Texas A&M University. His research focuses on building efficient and scalable machine learning systems with an emphasis on inference optimization.">
</head>

<!-- {% include toc %} -->

<!-- Computer Engineering | PhD candidate @ TAMU -->

<!-- I specialize in building efficient and scalable machine learning systems for real-world deployment. My research focuses on accelerating large-scale inference through hardware-aware design, sparsity, and parallelism. I am advised by [Dr. Narasimha Annapareddy](https://experts.tamu.edu/expert/narasimha-annapareddy/). -->

I specialize in building **efficient and scalable machine learning systems** for real-world deployment. My work bridges the gap between algorithm design and system-level efficiency, with a focus on **accelerating large-scale inference** through hardware-aware design, sparsity, and parallelism.

I am a PhD candidate in Computer Engineering at **Texas A&M University**, advised by [Dr. Narasimha Annapareddy](https://experts.tamu.edu/expert/narasimha-annapareddy/). 

---
### Research Interests

- Efficient and Sparse LLM Inference
- Hybrid Parallelism for Large-Scale Distributed Inference

### Selected Publications

- **Polar Sparsity**: High Throughput Batched LLM Inferencing with Scalable Contextual Sparsity
**Susav Shrestha**, Brad Settlemyer, Nikoli Dryden, Narasimha Reddy. [arXiv:2505.14884](https://arxiv.org/abs/2505.14884) [Code](https://github.com/susavlsh10/Polar-Sparsity)  

- **ESPN**: Memory-Efficient Multi-vector Information Retrieval  
**Susav Shrestha**, Narasimha Reddy, Zongwang Li* In *Proceedings of ISMM 2024([ACM ](https://doi.org/10.1145/3652024.3665515)) [Code](https://github.com/susavlsh10/ESPN-v1)

## Selected Experience

- Research Intern, NVIDIA, Santa Clara 2025
- Research Intern, NVIDIA, Austin, TX 2024
- Research Intern, Samsung Semiconductor, San Jose, CA 2022  

### Updates
- ðŸ”¬ Started a **Research Internship at NVIDIA** for Summer 2025 in Santa Clara  
- ðŸ“„ Released new paper on [Polar Sparsity](https://arxiv.org/abs/2505.14884) with up to **2.2Ã— decoding speedup** in LLM inference  
